{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from IPython.display import display \n",
    "\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from data_collection.data_collector import DataCollector, mt5\n",
    "from future_inzenering.talib_indicators import TLIndicators\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-03-07 02:45:00</th>\n",
       "      <td>1.09030</td>\n",
       "      <td>1.09023</td>\n",
       "      <td>1.09045</td>\n",
       "      <td>1.09011</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-07 02:50:00</th>\n",
       "      <td>1.09024</td>\n",
       "      <td>1.09021</td>\n",
       "      <td>1.09033</td>\n",
       "      <td>1.09013</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-07 02:55:00</th>\n",
       "      <td>1.09022</td>\n",
       "      <td>1.09029</td>\n",
       "      <td>1.09035</td>\n",
       "      <td>1.09018</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-07 03:00:00</th>\n",
       "      <td>1.09030</td>\n",
       "      <td>1.09003</td>\n",
       "      <td>1.09035</td>\n",
       "      <td>1.08999</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-07 03:05:00</th>\n",
       "      <td>1.09003</td>\n",
       "      <td>1.08994</td>\n",
       "      <td>1.09009</td>\n",
       "      <td>1.08985</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Open    Close     High      Low  Volume\n",
       "Date                                                           \n",
       "2024-03-07 02:45:00  1.09030  1.09023  1.09045  1.09011     249\n",
       "2024-03-07 02:50:00  1.09024  1.09021  1.09033  1.09013     332\n",
       "2024-03-07 02:55:00  1.09022  1.09029  1.09035  1.09018     180\n",
       "2024-03-07 03:00:00  1.09030  1.09003  1.09035  1.08999     303\n",
       "2024-03-07 03:05:00  1.09003  1.08994  1.09009  1.08985     330"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_col = DataCollector()\n",
    "data = data_col.get_historical_data(symbol=\"EURUSD\", timeframe= mt5.TIMEFRAME_M5 )\n",
    "data.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Functions for creating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tl_indicators = TLIndicators()\n",
    "# t_data = tl_indicators.indicators_pattern_recognition_functions(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lag_features(data:pd.DataFrame, start:int=1, end:int|None=None, column:str=\"Close\")-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates lagged features for the specified column of the time series.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The original DataFrame containing the time series.\n",
    "    start (int): The starting lag (default 1).\n",
    "    end (int | None): The ending lag. If None, calculated as half the square root of the series length.\n",
    "    column (str): The name of the column for which to create lagged features (default \"Close\").\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The DataFrame with the lagged features added.\n",
    "    \"\"\"\n",
    "\n",
    "    df = data.copy()\n",
    "\n",
    "    if end is None:\n",
    "        n = len(data)\n",
    "        end = int((n / np.sqrt(n)) / 2)\n",
    "\n",
    "    for lag in range(start, end ):\n",
    "        df[f'lag_{lag}'] = df[column].shift(lag)\n",
    "\n",
    "    return df.dropna()\n",
    "\n",
    "# create_lag_features(data, end=5).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_smoothing(data: pd.DataFrame, alpha: float=.9, column: str = \"Close\") -> pd.DataFrame: \n",
    "    \"\"\"\n",
    "    Performs exponential smoothing on a time series.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The original DataFrame containing the time series.\n",
    "    alpha (float): The smoothing factor (0 < alpha <= 1).\n",
    "    column (str): The name of the column to smooth (defaults to \"Close\").\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with a column of smoothed values ​​added.\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    series = data[column].values\n",
    "    result = [series[0]] # first value is same as series\n",
    "    for n in range(1, len(series)):\n",
    "        result.append(alpha * series[n] + (1 - alpha) * result[n-1])\n",
    "   \n",
    "    \n",
    "    data[\"ES\"] = result\n",
    "    return data\n",
    "\n",
    "# exponential_smoothing(data, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_exponential_smoothing(data: pd.DataFrame, alpha: float=.9, beta: float=.1, column: str = \"Close\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Performs double exponential smoothing on a time series.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The original DataFrame containing the time series.\n",
    "    alpha (float): Smoothing factor for the level (0 < alpha <= 1).\n",
    "    beta (float): Smoothing factor for the trend (0 < beta <= 1).\n",
    "    column (str): The name of the column to smooth (defaults to \"Close\").\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with the smoothed column and forecast appended.\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    series = data[column].values\n",
    "    n = len(series)\n",
    "    result = [series[0]]\n",
    "    \n",
    "    # Initialization of level and trend\n",
    "    level = series[0]\n",
    "    trend = series[1] - series[0]\n",
    "    \n",
    "    for t in range(1, n):\n",
    "        value = series[t]\n",
    "        last_level, level = level, alpha * value + (1 - alpha) * (level + trend)\n",
    "        trend = beta * (level - last_level) + (1 - beta) * trend\n",
    "        result.append(level + trend)\n",
    "    \n",
    "    # Processing the last forecast\n",
    "    result.append(level + trend)\n",
    "    \n",
    "    \n",
    "    df = data.copy()\n",
    "    df[\"cccccccc\"] = result[:n] \n",
    "\n",
    "    return df\n",
    "\n",
    "# double_exponential_smoothing(data, alpha=0.5, beta=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HoltWinters:\n",
    "    \"\"\"\n",
    "    Holt-Winters model with Brutlag method for anomaly detection.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def _initial_trend(self) -> float:\n",
    "        \"\"\"Initializes the trend based on the first few seasons.\"\"\"\n",
    "        sum_trend = 0.0\n",
    "        for i in range(self._slen):\n",
    "            sum_trend += float(self._series.iloc[i + self._slen] - self._series.iloc[i]) / self._slen\n",
    "        return sum_trend / self._slen  \n",
    "\n",
    "    def _initial_seasonal_components(self) -> dict:\n",
    "        \"\"\"Initializes seasonal components.\"\"\"\n",
    "        seasonals = {}\n",
    "        season_averages = []\n",
    "        n_seasons = int(len(self._series) / self._slen)\n",
    "\n",
    "        # Calculate seasonal averages\n",
    "        for j in range(n_seasons):\n",
    "            season_avg = np.mean(self._series.iloc[self._slen * j:self._slen * j + self._slen])\n",
    "            season_averages.append(season_avg)\n",
    "\n",
    "        # Calculate initial seasonal values\n",
    "        for i in range(self._slen):\n",
    "            sum_of_vals_over_avg = 0.0\n",
    "            for j in range(n_seasons):\n",
    "                sum_of_vals_over_avg += self._series.iloc[self._slen * j + i] - season_averages[j]\n",
    "            seasonals[i] = sum_of_vals_over_avg / n_seasons\n",
    "\n",
    "        return seasonals\n",
    "\n",
    "    def triple_exponential_smoothing(self, data:pd.DataFrame, column:str= \"Close\", slen:int=12, \n",
    "                                     alpha:float=.9, beta:float=.2, gamma:float=0.1, n_preds:int=1, \n",
    "                                     scaling_factor:float = 1.96) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Performs triple exponential smoothing and returns a DataFrame with the results,\n",
    "        predicted values, upper and lower bounds, and model components.\n",
    "\n",
    "        Triple exponential smoothing includes:\n",
    "\n",
    "        1. **Level**: the smoothed value of the time series at the current time.\n",
    "\n",
    "        2. **Trend**: the change in level relative to the previous value.\n",
    "\n",
    "        3. **Seasonality**: cyclical fluctuations in the data that repeat at a certain periodicity.\n",
    "\n",
    "        Parameters:\n",
    "        - data (pd.DataFrame): The time series data containing the column with the time series to analyze.\n",
    "        - column (str): The name of the column in `data` that contains the time series. Defaults to \"Close\".\n",
    "        - slen (int): Season length (number of periods in one season). Determines the periodicity of seasonal fluctuations. Defaults to 24.\n",
    "        - alpha (float): The smoothing coefficient for the level. The value must be be in the range (0, 1]. Defines the weight for the time series level. Default is 0.5.\n",
    "        - beta (float): Trend smoothing coefficient. The value must be in the range (0, 1]. Defines the weight for trend. Default is 0.5.\n",
    "        - gamma (float): Seasonality smoothing coefficient. The value must be in the range (0, 1]. Defines the weight for seasonal variations. Default is 0.5.\n",
    "        - n_preds (int): Number of steps ahead to forecast. Defines the forecast horizon. Default is 1.\n",
    "        - scaling_factor (float): Brute-Lag confidence interval width. Defines how wide the confidence interval boundary will be. Default is 1.96 (for a 95% confidence interval).\n",
    "\n",
    "        Returned value:\n",
    "        - **Actual** (pd.Series): The actual values ​​of the time series.\n",
    "        - **Forecast** (pd.Series): The predicted values ​​of the time series as calculated by the model. These are the values ​​the model expects based on the current data and previous estimates.\n",
    "        - **Predicted_Deviation** (pd.Series): The deviation forecast values ​​calculated by the Brutlag algorithm. This value shows the uncertainty of the forecast.\n",
    "        - **Upper_Bound** (pd.Series): The upper bound of the forecast confidence interval. It is calculated as the forecast value plus the deviation value multiplied by the scaling factor.\n",
    "        - **Lower_Bound** (pd.Series): The lower bound of the forecast confidence interval. It is calculated as the forecast value minus the deviation value multiplied by the scaling factor.\n",
    "        - **Smooth** (pd.Series): Smoothed values ​​of the time series level. These values ​​take into account only the level without trend and seasonality.\n",
    "        - **Trend** (pd.Series): Estimated trend at each step. It is the change in level over time, taking into account only trends.\n",
    "        - **Season** (pd.Series): Seasonal components of the model at each step. They show cyclical fluctuations based on pre-calculated seasonal values.\n",
    "\n",
    "        Notes:\n",
    "        - The method produces forecasts for both historical data (within the original time series) and future values ​​(within the forecast horizon, `n_preds`).\n",
    "        - The bias and confidence interval bounds are increased with each forecast step, accounting for forecast uncertainty.\n",
    "        - The seasonal components and trend are calculated using historical data and the initial values ​​set in the `_initial_trend` and `_initial_seasonal_components` methods.\n",
    "\n",
    "        The returned DataFrame contains all the listed columns with data corresponding to the length of the time series plus the forecast horizon.\n",
    "\n",
    "        Return value:\n",
    "        - **pd.DataFrame**: DataFrame containing columns with actual and forecast values, biases, interval bounds, and model components.\n",
    "\n",
    "        Example usage: \n",
    "        ```python model = HoltWinters() \n",
    "        result_df = model.triple_exponential_smoothing() print(result_df.head(15)) ``` \n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "        self._series = data[column]\n",
    "        self._column = column\n",
    "        self._slen = slen\n",
    "        self._alpha = alpha\n",
    "        self._beta = beta\n",
    "        self._gamma = gamma\n",
    "        self._n_preds = n_preds\n",
    "        self._scaling_factor = scaling_factor\n",
    "        \n",
    "        result = []\n",
    "        smooth = []\n",
    "        trend = []\n",
    "        season = []\n",
    "        predicted_deviation = []\n",
    "        upper_bound = []\n",
    "        lower_bound = []\n",
    "\n",
    "        seasonals = self._initial_seasonal_components()\n",
    "        last_smooth = self._series.iloc[0]\n",
    "        current_trend = self._initial_trend()\n",
    "\n",
    "        for i in range(len(self._series) + self._n_preds):\n",
    "            if i == 0:\n",
    "                smooth_val = self._series.iloc[0]\n",
    "                result.append(self._series.iloc[0])\n",
    "                smooth.append(smooth_val)\n",
    "                trend.append(current_trend)\n",
    "                season.append(seasonals[i % self._slen])\n",
    "\n",
    "                predicted_deviation.append(0)\n",
    "\n",
    "                upper_bound.append(result[0] + self._scaling_factor * predicted_deviation[0])\n",
    "                lower_bound.append(result[0] - self._scaling_factor * predicted_deviation[0])\n",
    "\n",
    "                continue\n",
    "\n",
    "            if i >= len(self._series):\n",
    "                m = i - len(self._series) + 1\n",
    "                forecast = (smooth_val + m * current_trend) + seasonals[i % self._slen]\n",
    "                result.append(forecast)\n",
    "\n",
    "                # Увеличиваем неопределенность во время прогноза\n",
    "                predicted_deviation.append(predicted_deviation[-1] * 1.01)\n",
    "            else:\n",
    "                value = self._series.iloc[i]\n",
    "                last_smooth, smooth_val = smooth_val, self._alpha * (value - seasonals[i % self._slen]) + (1 - self._alpha) * (smooth_val + current_trend)\n",
    "                current_trend = self._beta * (smooth_val - last_smooth) + (1 - self._beta) * current_trend\n",
    "                seasonals[i % self._slen] = self._gamma * (value - smooth_val) + (1 - self._gamma) * seasonals[i % self._slen]\n",
    "                forecast = smooth_val + current_trend + seasonals[i % self._slen]\n",
    "                result.append(forecast)\n",
    "\n",
    "                # Отклонение рассчитывается по алгоритму Брутлага\n",
    "                predicted_deviation.append(self._gamma * np.abs(self._series.iloc[i] - result[i]) + (1 - self._gamma) * predicted_deviation[-1])\n",
    "\n",
    "            upper_bound.append(result[-1] + self._scaling_factor * predicted_deviation[-1])\n",
    "            lower_bound.append(result[-1] - self._scaling_factor * predicted_deviation[-1])\n",
    "\n",
    "            smooth.append(smooth_val)\n",
    "            trend.append(current_trend)\n",
    "            season.append(seasonals[i % self._slen])\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            'Forecast': result[:len(self._series)],\n",
    "            'Predicted_Deviation': predicted_deviation[:len(self._series)],\n",
    "            'Upper_Bound': upper_bound[:len(self._series)],\n",
    "            'Lower_Bound': lower_bound[:len(self._series)],\n",
    "            'Smooth': smooth[:len(self._series)],\n",
    "            'Trend': trend[:len(self._series)],\n",
    "            'Season': season[:len(self._series)]\n",
    "        }, index=self._series.index)\n",
    "\n",
    "        # Merge original data with results\n",
    "        return pd.merge(data, df, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "# hw = HoltWinters()\n",
    "# hw.triple_exponential_smoothing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_interval(data:pd.DataFrame, n:int=24, column:str=\"Close\", dropna:bool=True)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculates the confidence interval for the moving average of the specified column.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The original DataFrame containing the time series.\n",
    "    n (int): The window size for the moving standard deviation (default is 24).\n",
    "    column (str): The name of the column for which to calculate the confidence interval (default is \"Close\").\n",
    "    dropna (bool): If True, removes rows with NaN values ​​(default is True).\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with columns added for the upper and lower bounds of the confidence interval.\n",
    "    \"\"\"\n",
    "\n",
    "    df = data.copy()\n",
    "\n",
    "    if len(df) < n:\n",
    "        raise ValueError(f\"Data length ({len(df)}) is less than window size ({n}).\")\n",
    "\n",
    "    rolling_std = df[column].rolling(window=n).std()\n",
    "    \n",
    "    df['Conf_upper_interval'] = df[column] + 1.96 * rolling_std\n",
    "    df['Conf_lower_interval'] = df[column] - 1.96 * rolling_std\n",
    "\n",
    "    if dropna:\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# confidence_interval(data).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Default Settings for functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_param(model, data, param_grid, column_x=\"Close\", columns_y=\"Forecast\"):\n",
    "\n",
    "    # Create a list of all possible parameter combinations\n",
    "    grid = list(ParameterGrid(param_grid))\n",
    "\n",
    "    # Initialize the best parameters and the best metric score\n",
    "    best_params = None\n",
    "    best_score = float('inf')\n",
    "\n",
    "    # Iterate through the parameter grid\n",
    "    for params in grid:\n",
    "        df = model(data, **params)\n",
    "        \n",
    "        # Calculate the RMSE metric\n",
    "        rmse = np.sqrt(mean_squared_error(data[column_x], df[columns_y]))\n",
    "        \n",
    "        # Compare and save the best parameters\n",
    "        if rmse < best_score:\n",
    "            best_score = rmse\n",
    "            best_params = params\n",
    "\n",
    "    print(f\"Best Parameters: {best_params},\\nBest RMSE: {best_score}\")\n",
    "\n",
    "    return best_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 0.9},\n",
      "Best RMSE: 2.108625284846068e-05\n",
      "Best Parameters: {'alpha': 0.9, 'beta': 0.1},\n",
      "Best RMSE: 4.8412143519660664e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:510: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:510: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:510: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:510: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:510: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:510: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:510: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:510: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:510: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:510: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:510: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:510: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:510: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:510: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:510: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:510: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:510: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:510: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:510: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:510: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:510: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:510: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:510: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:510: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:510: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:510: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:510: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "/home/alex/miniconda3/envs/tr_env/lib/python3.10/site-packages/numpy/core/_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "es_param_grid = {\n",
    "    'alpha': np.arange(.1, 1, .1)\n",
    "}\n",
    "es_param = grid_search_param(exponential_smoothing, data, es_param_grid, columns_y=\"ES\")\n",
    "\n",
    "\n",
    "des_param_grid = {\n",
    "    'alpha': np.arange(.1, 1, .1),\n",
    "    'beta': np.arange(.1, 1, .1)\n",
    "}\n",
    "des_param = grid_search_param(double_exponential_smoothing, data, des_param_grid, columns_y=\"DES\")\n",
    "\n",
    "\n",
    "model = HoltWinters().triple_exponential_smoothing\n",
    "hw_param_grid = {\n",
    "    'alpha': np.arange(.1, 1, .1),\n",
    "    'beta': np.arange(.1, 1, .1),\n",
    "    'gamma': np.arange(.1, 1, .1),\n",
    "    'slen': np.arange(3, 31, 2),\n",
    "}\n",
    "hw_param = grid_search_param(model, data, hw_param_grid)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting all methods into one class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicFuture(HoltWinters):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
